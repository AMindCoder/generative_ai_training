## ğŸ” What is Self-Attention?

Self-attention is a mechanism used in Transformer models to allow each word (token) in a sequence to "look at" or **attend to** other words in the same sequence to better understand context. Itâ€™s how models like GPT and BERT learn context and meaning.

![Self-Attention Mechanism](self_attention.png)

---

## ğŸ§  Letâ€™s Use This Example:

> Input sentence: **â€œHow are you doing?â€**

---

### âœ… Step 1: Token Embedding

Each word gets converted into a **dense vector** via a word/token embedding layer. So you get 5 vectors â€” one for each word:
**\[How], \[are], \[you], \[doing], \[?]**

---

### âœ… Step 2: Create Queries (Q), Keys (K), and Values (V)

Each embedded word vector is passed through **three separate linear layers** (just matrices) to create:

* **Query (Q)**: What this word is looking for.
* **Key (K)**: What this word offers to others.
* **Value (V)**: What content it shares with others.

All of these have the same hidden dimension size.

From the image:

* Magenta block â†’ Keys (Wk)
* Orange block â†’ Queries (Wq)
* Green block â†’ Values (Wv)

---

### âœ… Step 3: Calculate Attention Scores

Letâ€™s focus on the word **â€œHowâ€**.

To understand how much attention **â€œHowâ€** should give to other words, we:

1. Take the **Query vector for â€œHowâ€**
2. Dot-product it with **Key vectors of all words** (including itself)
3. This gives us a **score** for each word.

Mathematically:

```
score(how, are) = Q_how Â· K_are^T
```

Do this for all token pairs in the sequence.

---

### âœ… Step 4: Softmax Scores

These raw scores are passed through a **softmax** to turn them into **weights that sum to 1** (aka attention distribution).

Example for **â€œHowâ€**:

```
[0.1, 0.2, 0.3, 0.3, 0.1]  â†’ "How" pays 30% attention to "you" and "doing"
```

---

### âœ… Step 5: Multiply with Values

Each word's **Value (V)** vector is multiplied by the corresponding attention score.

So the new **representation of â€œHowâ€** becomes:

```
Z_how = sum(attention_weights * Value_vectors)
```

Do this for each word in the sequence.

---

## ğŸ¯ Final Output

You now have **new vectors** (Z vectors) for each word that include **contextual information** from other words â€” all computed in parallel.

---

## ğŸ§ª Real Use-Case Impact

For example, in:

> **"He fed the dog because it was hungry."**

To interpret â€œitâ€, the model needs to attend more to â€œdogâ€ than â€œheâ€.
Self-attention allows it to do just that â€” by assigning higher attention weights to â€œdogâ€ when evaluating â€œitâ€.

---

## Summary of Flow:

```
Input tokens â†’ Embeddings â†’ Q, K, V â†’
Dot-product(Q, K) â†’ Softmax â†’ Attention Weights â†’
Attention Weights Ã— V â†’ Contextual Output
```

