{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Building a Q&A Bot with Iterative Prompt Refinement\n",
    "\n",
    "## Objectives\n",
    "- Build a Q&A system with context awareness\n",
    "- Implement prompt refinement techniques\n",
    "- Learn best practices for prompt engineering\n",
    "- Understand conversation management\n",
    "\n",
    "## Prerequisites\n",
    "- Completed Module 1\n",
    "- OpenAI API key configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Q&A System with Context Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationManager:\n",
    "    def __init__(self, max_history: int = 5):\n",
    "        self.conversation_history: List[Dict] = []\n",
    "        self.max_history = max_history\n",
    "    \n",
    "    def add_message(self, role: str, content: str):\n",
    "        self.conversation_history.append({\"role\": role, \"content\": content})\n",
    "        if len(self.conversation_history) > self.max_history * 2:  # *2 because each exchange has 2 messages\n",
    "            self.conversation_history = self.conversation_history[-self.max_history * 2:]\n",
    "    \n",
    "    def get_messages(self) -> List[Dict]:\n",
    "        return self.conversation_history\n",
    "\n",
    "class QABot:\n",
    "    def __init__(self, system_prompt: str = None):\n",
    "        self.conversation = ConversationManager()\n",
    "        if system_prompt:\n",
    "            self.conversation.add_message(\"system\", system_prompt)\n",
    "    \n",
    "    def get_response(self, user_input: str) -> str:\n",
    "        self.conversation.add_message(\"user\", user_input)\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=self.conversation.get_messages(),\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        assistant_response = response.choices[0].message.content\n",
    "        self.conversation.add_message(\"assistant\", assistant_response)\n",
    "        \n",
    "        return assistant_response\n",
    "\n",
    "# Test the basic Q&A system\n",
    "system_prompt = \"\"\"You are a knowledgeable AI assistant specializing in technology and programming.\n",
    "Always provide clear, concise answers with examples when appropriate.\"\"\"\n",
    "\n",
    "qa_bot = QABot(system_prompt)\n",
    "\n",
    "questions = [\n",
    "    \"What is machine learning?\",\n",
    "    \"Can you give me an example of supervised learning?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"User: {question}\")\n",
    "    response = qa_bot.get_response(question)\n",
    "    print(f\"Assistant: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing Prompt Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefinedQABot(QABot):\n",
    "    def __init__(self, system_prompt: str = None):\n",
    "        super().__init__(system_prompt)\n",
    "    \n",
    "    def refine_question(self, user_input: str) -> str:\n",
    "        refinement_prompt = f\"\"\"\n",
    "        Please analyze and refine the following question to make it more specific and answerable:\n",
    "        Question: {user_input}\n",
    "        \n",
    "        If the question is vague, add relevant context or specifications.\n",
    "        If the question is complex, break it down into smaller parts.\n",
    "        If the question is clear and specific, return it as is.\n",
    "        \n",
    "        Refined question:\n",
    "        \"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": refinement_prompt}],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def get_response(self, user_input: str, refine: bool = True) -> str:\n",
    "        if refine:\n",
    "            refined_question = self.refine_question(user_input)\n",
    "            print(f\"Refined question: {refined_question}\\n\")\n",
    "            return super().get_response(refined_question)\n",
    "        return super().get_response(user_input)\n",
    "\n",
    "# Test the refined Q&A system\n",
    "refined_bot = RefinedQABot(system_prompt)\n",
    "\n",
    "vague_questions = [\n",
    "    \"How do I start coding?\",\n",
    "    \"What's the best way to learn AI?\"\n",
    "]\n",
    "\n",
    "for question in vague_questions:\n",
    "    print(f\"User: {question}\")\n",
    "    response = refined_bot.get_response(question)\n",
    "    print(f\"Assistant: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding Domain-Specific Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgrammingQABot(RefinedQABot):\n",
    "    def __init__(self):\n",
    "        system_prompt = \"\"\"\n",
    "        You are an expert programming tutor specializing in Python and AI development.\n",
    "        Follow these guidelines:\n",
    "        1. Always include code examples when appropriate\n",
    "        2. Explain concepts step by step\n",
    "        3. Suggest best practices and common pitfalls\n",
    "        4. Reference official documentation when relevant\n",
    "        \"\"\"\n",
    "        super().__init__(system_prompt)\n",
    "        \n",
    "        self.code_templates = {\n",
    "            \"function\": \"def function_name(parameters):\\n    \"\"\"Docstring.\"\"\"\\n    # Function body\\n    return result\",\n",
    "            \"class\": \"class ClassName:\\n    \"\"\"Class docstring.\"\"\"\\n    def __init__(self):\\n        # Initialize attributes\\n        pass\"\n",
    "        }\n",
    "    \n",
    "    def format_code_response(self, code: str) -> str:\n",
    "        return f\"```python\\n{code}\\n```\"\n",
    "    \n",
    "    def get_response(self, user_input: str) -> str:\n",
    "        if \"example\" in user_input.lower() and \"code\" in user_input.lower():\n",
    "            # Add code template to the conversation context\n",
    "            template_prompt = f\"Include relevant code template in your response. Here's a basic template: {self.format_code_response(self.code_templates['function'])}\"\n",
    "            self.conversation.add_message(\"system\", template_prompt)\n",
    "        \n",
    "        return super().get_response(user_input)\n",
    "\n",
    "# Test the programming-specific Q&A bot\n",
    "programming_bot = ProgrammingQABot()\n",
    "\n",
    "programming_questions = [\n",
    "    \"Can you show me an example of a Python function that calculates factorial?\",\n",
    "    \"How do I create a simple class in Python?\"\n",
    "]\n",
    "\n",
    "for question in programming_questions:\n",
    "    print(f\"User: {question}\")\n",
    "    response = programming_bot.get_response(question)\n",
    "    print(f\"Assistant: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing Feedback Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackQABot(ProgrammingQABot):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feedback_history = []\n",
    "    \n",
    "    def incorporate_feedback(self, question: str, response: str, feedback: str) -> str:\n",
    "        feedback_prompt = f\"\"\"\n",
    "        Original question: {question}\n",
    "        Previous response: {response}\n",
    "        User feedback: {feedback}\n",
    "        \n",
    "        Please provide an improved response addressing the feedback.\n",
    "        \"\"\"\n",
    "        \n",
    "        improved_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI tutor focused on providing improved responses based on user feedback.\"},\n",
    "                {\"role\": \"user\", \"content\": feedback_prompt}\n",
    "            ],\n",
    "            temperature=0.5\n",
    "        )\n",
    "        \n",
    "        return improved_response.choices[0].message.content\n",
    "    \n",
    "    def get_response_with_feedback(self, question: str, feedback: str = None) -> str:\n",
    "        if feedback and self.feedback_history:\n",
    "            last_question, last_response = self.feedback_history[-1]\n",
    "            improved_response = self.incorporate_feedback(last_question, last_response, feedback)\n",
    "            self.feedback_history.append((question, improved_response))\n",
    "            return improved_response\n",
    "        \n",
    "        response = self.get_response(question)\n",
    "        self.feedback_history.append((question, response))\n",
    "        return response\n",
    "\n",
    "# Test the feedback system\n",
    "feedback_bot = FeedbackQABot()\n",
    "\n",
    "# Initial question\n",
    "question = \"How do I use a for loop in Python?\"\n",
    "print(f\"User: {question}\")\n",
    "response = feedback_bot.get_response_with_feedback(question)\n",
    "print(f\"Assistant: {response}\\n\")\n",
    "\n",
    "# Provide feedback and get improved response\n",
    "feedback = \"Could you provide more examples with different use cases?\"\n",
    "print(f\"User feedback: {feedback}\")\n",
    "improved_response = feedback_bot.get_response_with_feedback(question, feedback)\n",
    "print(f\"Assistant (improved): {improved_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Implement a specialized Q&A bot for a specific programming language or framework\n",
    "2. Add support for code execution and validation in the responses\n",
    "3. Implement a rating system for responses and use it to improve future answers\n",
    "4. Create a system that can generate practice exercises based on the user's questions\n",
    "\n",
    "## Next Steps\n",
    "- Explore more advanced prompt engineering techniques\n",
    "- Implement support for multiple programming languages\n",
    "- Add code analysis and suggestions for improvement\n",
    "- Integrate with development environments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
